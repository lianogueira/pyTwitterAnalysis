{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyTwitterAnalysis.pyTwitterAnalysis import tw_analysis\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "\n",
    "#db connection\n",
    "mongoDBConnectionSTR = \"mongodb://localhost:27017\"\n",
    "client = MongoClient(mongoDBConnectionSTR)\n",
    "db = client.twitter_DB_MeToo_Test #chose your DB name here\n",
    "db = client.twitter_DB_Tst #chose your DB name here\n",
    "#db = client.twitter_DB_BJJ_en_test1 #chose your DB name here\n",
    "db = client.myTwitterDB_MeToo_bkp_tst #chose your DB name here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select where you want to save the files\n",
    "###### This path should be different for every database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = 'D:\\\\Data\\\\Experiments\\\\metooDB'\n",
    "#BASE_PATH = 'D:\\\\Data\\\\Experiments\\\\bjjenDB'\n",
    "\n",
    "x = tw_analysis(BASE_PATH, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create all edges for that db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.export_mult_types_edges_for_input(type_of_graph = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print EDA\n",
    "###### Save the results on the spreasheet - (Tab \"Graphs-EDA-Data\")\n",
    "###### Please also save the EDA.txt files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.eda_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Community Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choose the graph type to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TYPE OF GRAPH ANALYSIS\n",
    "########################################################\n",
    "# Type of graph analysis\n",
    "# Options: user_conn_all,       --All user connections\n",
    "#          user_conn_mention,   --Only Mentions user connections\n",
    "#          user_conn_retweet,   --Only Retweets user connections\n",
    "#          user_conn_reply,     --Only Replies user connections\n",
    "#          user_conn_quote,     --Only Quotes user connections\n",
    "#          ht_conn              --Hashtag connects - (Hashtgs that wereused together)\n",
    "\n",
    "TYPE_OF_GRAPH = 'user_conn_all'\n",
    "#------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load graph with the edge file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_prefix_str = ''\n",
    "case_ht_str = ''\n",
    "if TYPE_OF_GRAPH == 'user_conn_all':\n",
    "    edge_prefix_str = 'UserConnections_'                \n",
    "elif TYPE_OF_GRAPH == 'user_conn_mention':\n",
    "    edge_prefix_str = 'MentionUserConnections_'    \n",
    "elif TYPE_OF_GRAPH == 'user_conn_retweet':\n",
    "    edge_prefix_str = 'RetweetUserConnections_'    \n",
    "elif TYPE_OF_GRAPH == 'user_conn_reply':\n",
    "    edge_prefix_str = 'ReplyUserConnections_'    \n",
    "elif TYPE_OF_GRAPH == 'user_conn_quote':\n",
    "    edge_prefix_str = 'QuoteUserConnections_'    \n",
    "elif TYPE_OF_GRAPH== 'ht_conn':\n",
    "    edge_prefix_str = 'HTConnection_'\n",
    "    case_ht_str = 'ht_'  \n",
    "        \n",
    "edge_file_path = BASE_PATH + '\\\\data_input_files\\\\' + edge_prefix_str + 'AllPeriods_' + case_ht_str + 'edges.txt'\n",
    "\n",
    "\n",
    "#edge_file_path = 'D:\\\\Data\\\\tests\\\\bjj8\\\\data_input_files\\\\AllPeriods_edges.txt'         \n",
    "#edge_file_path = 'D:\\\\Data\\\\tests\\\\mt2\\\\data_input_files\\\\AllPeriods_ExcludingBots_edges.txt' \n",
    "G = x.loadGraphFromFile(edge_file_path)\n",
    "G = x.largest_component_no_self_loops(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate louvain_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating...\")\n",
    "starttime = time.time()\n",
    "G, labels, k = x.calculate_louvain_clustering(G)\n",
    "endtime = time.time()\n",
    "print(\"Execution Time:  %s seconds \" % (endtime - starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate spectral_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating...\")\n",
    "starttime = time.time()\n",
    "G, labels, k = x.calculate_spectral_clustering(G, k=k)\n",
    "endtime = time.time()\n",
    "print(\"Execution Time:  %s seconds \" % (endtime - starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print clustering metrics for community_louvain clustering method\n",
    "###### Save the results on the spreasheet - (Tab \"Graphs-CommtyData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.print_commty_cluster_metrics(G, comm_att = 'community_louvain', ignore_cmmty_lt=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print clustering metrics for community_spectral clustering method\n",
    "###### Save the results on the spreasheet - (Tab \"Graphs-CommtyData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.print_commty_cluster_metrics(G, comm_att = 'community_spectral', ignore_cmmty_lt=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print clustering metrics for the top 25 nodes clusters\n",
    "###### Save the results on the spreasheet - (Tab \"Graphs-CommtyData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.print_top_nodes_cluster_metrics(G, 25, acc_node_size_cutoff=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.plot_disconnected_graph_distr(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.plot_disconnected_graph_distr(G, size_cutoff=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_FILES_PATH = 'D:\\\\Data\\\\tests\\\\my_json_files'  ##this is the folder path where all of your twitter json files should be\n",
    "x.loadDocFromFile(JSON_FILES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bots_list_file = None #'C:\\\\Users\\\\Lia\\\\Dropbox\\\\School\\\\1-Texas State classes\\\\2020-01-Thesis\\\\JLab\\\\GitHub\\\\DataLab-GitHub-toUpload\\\\twitterAnalysis\\\\src\\\\data_files\\\\bots_user_ids_list.txt'\n",
    "step = 100000   # You can set the number of tweets to load at a time. (Large number may cause out of memory errors, low number may take a long time to run)\n",
    "x.build_db_collections(step, bots_ids_list_file=bots_list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format: Period Name, Period Start Date, Period End Date\n",
    "period_arr = [['P1',  '10/08/2017 00:00:00', '10/15/2017 00:00:00'],\n",
    "              ['P2',  '10/15/2017 00:00:00', '10/29/2017 00:00:00'],\n",
    "              ['P3',  '10/29/2017 00:00:00', '11/12/2017 00:00:00'],\n",
    "              ['P4',  '11/12/2017 00:00:00', '11/26/2017 00:00:00'],\n",
    "              ['P5',  '11/26/2017 00:00:00', '12/10/2017 00:00:00'],\n",
    "              ['P6',  '12/10/2017 00:00:00', '12/24/2017 00:00:00'],              \n",
    "              ['P7',  '12/24/2017 00:00:00', '01/07/2018 00:00:00'],              \n",
    "              ['P8',  '01/07/2018 00:00:00', '01/21/2018 00:00:00'],\n",
    "              ['P9',  '01/21/2018 00:00:00', '02/04/2018 00:00:00'],              \n",
    "              ['P10', '02/04/2018 00:00:00', '02/18/2018 00:00:00'],\n",
    "              ['P11', '02/18/2018 00:00:00', '03/04/2018 00:00:00'],\n",
    "              ['P12', '03/04/2018 00:00:00', '03/19/2018 00:00:00']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format: Period Name, Period Start Date, Period End Date\n",
    "period_arr = [['P1',  '01/01/2020 00:00:00', '05/01/2020 00:00:00'],\n",
    "              ['P2',  '05/01/2020 00:00:00', '05/20/2020 00:00:00'],\n",
    "              ['P3',  '05/20/2020 00:00:00', '06/15/2020 00:00:00'],\n",
    "              ['P4',  '06/15/2020 00:00:00', '06/30/2020 00:00:00'],\n",
    "              ['P5',  '06/30/2020 00:00:00', '07/28/2020 00:00:00']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bots_list_file = 'C:/Users/Lia/Dropbox/School/1-Texas State classes/2020-01-Thesis/JLab/GitHub/DataLab-GitHub-toUpload - Copy/twitterAnalysis/src/data_files/bots_user_ids_list.txt'\n",
    "\n",
    "# You can set the number of tweets to load at a time. (Large number may cause out of memory errors, low number may take a long time to run)\n",
    "step = 100000\n",
    "\n",
    "#build collections\n",
    "x.build_db_collections(step, bots_ids_list_file=bots_list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_conn_all, user_conn_mention, user_conn_retweet, user_conn_reply, user_conn_quote, ht_conn\n",
    "x.export_mult_types_edges_for_input(period_arr=period_arr, type_of_graph = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.eda_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TYPE OF GRAPH ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TYPE OF GRAPH ANALYSIS\n",
    "########################################################\n",
    "# Type of grpah analysis\n",
    "# Options: user_conn_all,       --All user connections\n",
    "#          user_conn_mention,   --Only Mentions user connections\n",
    "#          user_conn_retweet,   --Only Retweets user connections\n",
    "#          user_conn_reply,     --Only Replies user connections\n",
    "#          user_conn_quote,     --Only Quotes user connections\n",
    "#          ht_conn              --Hashtag connects - (Hashtgs that wereused together)\n",
    "\n",
    "TYPE_OF_GRAPH = 'user_conn_retweet'\n",
    "#------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OUTPUT PATH, PERIOD AND BOT SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OUTPUT PATH, PERIOD AND BOT SETTINGS\n",
    "########################################################\n",
    "\n",
    "# Path where you want to save your ouput files\n",
    "# It will use the path you already set previouly, \n",
    "# but you can change here in case you want a new path\n",
    "OUTPUT_PATH = BASE_PATH  \n",
    "\n",
    "#Filter bots or not. Options: (None, '0', or '1')\n",
    "IS_BOT_FILTER = None\n",
    "\n",
    "#Same period array you already set previously. \n",
    "#You can change here in case you want something new, \n",
    "#just follow the same format as array in previous step\n",
    "PERIOD_ARR = period_arr        \n",
    "#------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FILES TO CREATE OPTIONS\n",
    "###### Choose which files you want to create - Options: (Y/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILES TO CREATE OPTIONS\n",
    "# Choose which files you want to create - Options: (Y/N)\n",
    "########################################################\n",
    "\n",
    "\n",
    "# Creates a separate folder for the top degree nodes\n",
    "#------------------------------------------------------------\n",
    "CREATE_TOP_NODES_FILES_FLAG = 'Y'\n",
    "# IF you chose CREATE_TOP_NODES_FILES_FLAG='Y', you can also set these settings\n",
    "# We will create subfolder for the top degree nodes based on these number\n",
    "TOP_DEGREE_START = 1   \n",
    "TOP_DEGREE_END = 25\n",
    "# We will create subfolders for the top degree nodes \n",
    "# for each period based on these numbers\n",
    "PERIOD_TOP_DEGREE_START = 1\n",
    "PERIOD_TOP_DEGREE_END = 10\n",
    "\n",
    "\n",
    "# Creates files with the edges of each folder, \n",
    "#------------------------------------------------------------\n",
    "# and a list of nodes and their degree\n",
    "CREATE_NODES_EDGES_FILES_FLAG = 'Y'\n",
    "\n",
    "\n",
    "# Creates graph visualization files\n",
    "#------------------------------------------------------------\n",
    "CREATE_GRAPHS_FILES_FLAG = 'Y'\n",
    "\n",
    "\n",
    "# Creates files for topic discovery\n",
    "#------------------------------------------------------------\n",
    "# Tweet texts for that folder, word cloud, and LDA Model Visualization\n",
    "CREATE_TOPIC_MODEL_FILES_FLAG = 'Y'\n",
    "# If you chose CREATE_TOPIC_MODEL_FILES_FLAG='Y', you can also set this setting\n",
    "# This is the number of topics to send as input to LDA model (Default is 4)\n",
    "NUM_OF_TOPICS = 4\n",
    "\n",
    "\n",
    "# Creates files with ht frequency\n",
    "#------------------------------------------------------------\n",
    "# Text files with all hashtags used, wordcloud, and barchart\n",
    "CREATE_HT_FREQUENCY_FILES_FLAG = 'Y'\n",
    "\n",
    "\n",
    "# Creates files with word frequency\n",
    "#------------------------------------------------------------\n",
    "# Text files with all hashtags used, wordcloud, and barchart\n",
    "CREATE_WORDS_FREQUENCY_FILES_FLAG = 'Y'\n",
    "# If you answer yes to CREATE_WORDS_FREQUENCY_FILES_FLAG, then you can choose\n",
    "# how many words you want to see in you list file.\n",
    "# The number of words to save on the frequency word list file. (Default=5000)\n",
    "TOP_NO_WORD_FILTER = None   \n",
    "\n",
    "\n",
    "# Creates files with time series data\n",
    "#------------------------------------------------------------\n",
    "CREATE_TIMESERIES_FILES_FLAG = 'Y'\n",
    "\n",
    "\n",
    "# Creates graphs with hashtag information\n",
    "#------------------------------------------------------------\n",
    "# This can be used when you analyzing user connections, \n",
    "# but still want to see the hashtag connection graph for that group of users\n",
    "CREATE_HT_CONN_FILES_FLAG = 'Y'\n",
    "# IF you chose CREATE_HT_CONN_FILES_FLAG = 'Y', you can also set this setting\n",
    "# This is to ignore the top hashtags in the visualization\n",
    "# Sometimes ignoreing the main hashtag can be helpfull invisualization to\n",
    "# discovery other important structure within the graph\n",
    "TOP_HT_TO_IGNORE = 2\n",
    "\n",
    "\n",
    "# Creates louvain communities folder and files\n",
    "#------------------------------------------------------------\n",
    "CREATE_COMMUNITY_FILES_FLAG = 'N'\n",
    "# If set CREATE_COMMUNITY_FILES_FLAG = 'Y', then you can\n",
    "# set a cutoff number of edges to identify when a folder should be created\n",
    "# If the commty has less edges than this number, it won't create a new folder\n",
    "# Default is 200\n",
    "COMMTY_EDGE_SIZE_CUTOFF = 200 \n",
    "#------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "## GRAPH OPTIONS #######################################\n",
    "########################################################\n",
    "\n",
    "# This is a percentage number used to remove nodes\n",
    "# so we can be able to plot large graphs. \n",
    "# You can run this logic multiple times with different percentages. \n",
    "# Each time the logic will save the graph file with a different name \n",
    "# according to the parameter given\n",
    "REDUCED_GRAPH_COMTY_PER = 1\n",
    "    \n",
    "# This is the number of edges cutoff to decide if we will print \n",
    "# the graph or not. The logic will remove nodes until it can get \n",
    "# to this max number of edges to plot\n",
    "# If you choose a large number it may take a long time to run. \n",
    "# If you choose a small number it may contract nodes too much or not print the graph at all\n",
    "GRAPH_PLOT_CUTOFF_NO_NODES = 2000\n",
    "GRAPH_PLOT_CUTOFF_NO_EDGES = 8000\n",
    "\n",
    "\n",
    "CREATE_GRAPH_WITHOUT_NODE_SCALE_FLAG = 'Y'\n",
    "CREATE_GRAPH_WITH_NODE_SCALE_FLAG = 'Y'\n",
    "CREATE_REDUCED_GRAPH_FLAG = 'Y'\n",
    "REDUCED_GRAPH_REMOVE_EDGE_WEIGHT = None   #None if you don't want\n",
    "REDUCED_GRAPH_REMOVE_EDGES_UNTIL_CUTOFF_FLAG = 'Y'\n",
    "#------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Set configurations\n",
    "x.setConfigs(type_of_graph=TYPE_OF_GRAPH,\n",
    "            is_bot_Filter=IS_BOT_FILTER,\n",
    "            period_arr=PERIOD_ARR,\n",
    "            create_nodes_edges_files_flag=CREATE_NODES_EDGES_FILES_FLAG, \n",
    "            create_graphs_files_flag=CREATE_GRAPHS_FILES_FLAG,\n",
    "            create_topic_model_files_flag=CREATE_TOPIC_MODEL_FILES_FLAG,\n",
    "            create_ht_frequency_files_flag=CREATE_HT_FREQUENCY_FILES_FLAG,\n",
    "            create_words_frequency_files_flag=CREATE_WORDS_FREQUENCY_FILES_FLAG,\n",
    "            create_timeseries_files_flag=CREATE_TIMESERIES_FILES_FLAG,\n",
    "            create_top_nodes_files_flag=CREATE_TOP_NODES_FILES_FLAG, \n",
    "            create_community_files_flag=CREATE_COMMUNITY_FILES_FLAG,\n",
    "            create_ht_conn_files_flag=CREATE_HT_CONN_FILES_FLAG,\n",
    "            num_of_topics=NUM_OF_TOPICS, \n",
    "            top_no_word_filter=TOP_NO_WORD_FILTER, \n",
    "            top_ht_to_ignore=TOP_HT_TO_IGNORE,\n",
    "            graph_plot_cutoff_no_nodes=GRAPH_PLOT_CUTOFF_NO_NODES, \n",
    "            graph_plot_cutoff_no_edges=GRAPH_PLOT_CUTOFF_NO_EDGES,\n",
    "            create_graph_without_node_scale_flag=CREATE_GRAPH_WITHOUT_NODE_SCALE_FLAG, \n",
    "            create_graph_with_node_scale_flag=CREATE_GRAPH_WITH_NODE_SCALE_FLAG, \n",
    "            create_reduced_graph_flag=CREATE_REDUCED_GRAPH_FLAG,\n",
    "            reduced_graph_comty_contract_per=REDUCED_GRAPH_COMTY_PER,\n",
    "            reduced_graph_remove_edge_weight=REDUCED_GRAPH_REMOVE_EDGE_WEIGHT, \n",
    "            reduced_graph_remove_edges=REDUCED_GRAPH_REMOVE_EDGES_UNTIL_CUTOFF_FLAG,                            \n",
    "            top_degree_start=TOP_DEGREE_START, \n",
    "            top_degree_end=TOP_DEGREE_END, \n",
    "            period_top_degree_start=PERIOD_TOP_DEGREE_START, \n",
    "            period_top_degree_end=PERIOD_TOP_DEGREE_END, \n",
    "            commty_edge_size_cutoff=COMMTY_EDGE_SIZE_CUTOFF\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.edge_files_analysis(output_path=OUTPUT_PATH)\n",
    "\n",
    "print(\"**** END ****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_file_path = 'D:\\\\Data\\\\tests\\\\bjj8\\\\data_input_files\\\\AllPeriods_edges.txt'         \n",
    "#edge_file_path = 'D:\\\\Data\\\\tests\\\\mt2\\\\data_input_files\\\\AllPeriods_ExcludingBots_edges.txt'         \n",
    "\n",
    "G = x.loadGraphFromFile(edge_file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G3 = x.largest_component_no_self_loops(G) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2, labels, k = x.calculate_louvain_clustering(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_att = 'community_louvain'\n",
    "\n",
    "#find the number of communities in the graph\n",
    "no_of_comm = max(nx.get_node_attributes(G2, comm_att).values())+1    \n",
    "\n",
    "#loop through the communities and get the top nodes for each communities based on the given percentage\n",
    "for commty in range(no_of_comm):\n",
    "    print(commty)\n",
    "    #find subgraphs of this community\n",
    "    com_sub_graph = G2.subgraph([n for n,attrdict in G2.node.items() if attrdict [comm_att] == commty ])\n",
    "    print(len(com_sub_graph.edges()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = nx.graph_clique_number(G)\n",
    "cn\n",
    "#19\n",
    "#14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn3 = nx.graph_clique_number(G3)\n",
    "cn4 = nx.graph_number_of_cliques(G3)\n",
    "cn3\n",
    "#19\n",
    "#14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn4 = nx.graph_number_of_cliques(G3)\n",
    "cn4\n",
    "#2939079\n",
    "#105740"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn4 = nx.graph_number_of_cliques(G)\n",
    "cn4\n",
    "#2970444\n",
    "#124486"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = nx.average_clustering(G)\n",
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x.plot_disconnected_graph_distr(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = nx.average_clustering(G)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_no_of_nodes = len(G.nodes())\n",
    "tot_no_of_nodes   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_degree_list = list(sorted(G.degree, key=lambda x: x[1], reverse=True)) \n",
    "\n",
    "node_degree_list[0:3]\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_subgraph_edges = nx.Graph()\n",
    "G_subgraph_edges = G.edge_subgraph(G.edges(['BretBaier','ChrisEvans', 'GOPLeader']))\n",
    "G_subgraph = G.subgraph(G_subgraph_edges.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(G_subgraph.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr_ndoes = list(x.get_top_degree_nodes(G, 1, 3))\n",
    "np.flip(arr_ndoes, 0)\n",
    "\n",
    "arr = []\n",
    "for f in list(x.get_top_degree_nodes(G, 1, 3)):\n",
    "    arr.append(f[0])\n",
    "    \n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3 = x.create_node_subgraph(G, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(g3.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_comt = pd.DataFrame.from_dict(nx.get_node_attributes(G, 'community_louvain'),  orient='index').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for x in range(len(arr_comt)):\n",
    "    if i > 10:\n",
    "        break\n",
    "        \n",
    "    print(x)\n",
    "#    G_subgraph = G.subgraph(G_subgraph_edges.nodes())\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes('community_louvain'='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color=nx.get_node_attributes(G2,'community_louvain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#color[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "#user_community_df = pd.DataFrame.from_dict(labels,  orient='index')\n",
    "#user_community_df.columns = ['community_louvain'] # modularity class is community number\n",
    "#user_community_df.index.rename('user_name' , inplace=True)\n",
    "#user_community_df.head() # preview community assigments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(nx.get_node_attributes(G, 'community_louvain'),  orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(arr_comt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_comt[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in arr:\n",
    "    print(x)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1, f = x.queryData(exportType='tweetCountByLanguage', filepath='', inc=0)\n",
    "print(arr1)\n",
    "\n",
    "arr2, f = x.queryData(exportType='tweetCountByMonth', filepath='', inc=0)\n",
    "print(arr2)     \n",
    "\n",
    "arr3, f = x.queryData(exportType='tweetCountByFile', filepath='', inc=0)\n",
    "print(arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "\n",
    "total_count = 0\n",
    "tweet_user_count = 0\n",
    "reply_user_count = 0\n",
    "quote_user_count = 0\n",
    "retweet_user_count = 0\n",
    "\n",
    "select_cTweet = db.users.aggregate( [{\"$group\": {\"_id\": {\"user_type\": \"$user_type\"}, \"count\": { \"$sum\": 1 } } } ])\n",
    "for tweetCount in select_cTweet:   \n",
    "    total_count = total_count + tweetCount[\"count\"]\n",
    "    if tweetCount[\"_id\"][\"user_type\"] == 'tweet':\n",
    "        arr.append([ '1', tweetCount[\"_id\"][\"user_type\"], 'Users with at least one document in this db', str(tweetCount[\"count\"]) ])                                \n",
    "    elif tweetCount[\"_id\"][\"user_type\"] == 'retweet':\n",
    "        arr.append([ '2', tweetCount[\"_id\"][\"user_type\"], 'Users that were retweeted, but are not part of previous group', str(tweetCount[\"count\"]) ])                        \n",
    "    elif tweetCount[\"_id\"][\"user_type\"] == 'quote':\n",
    "        arr.append([ '3', tweetCount[\"_id\"][\"user_type\"], 'Users that were quote, but are not part of previous groups', str(tweetCount[\"count\"]) ])                \n",
    "    elif tweetCount[\"_id\"][\"user_type\"] == 'reply':\n",
    "        arr.append([ '4', tweetCount[\"_id\"][\"user_type\"], 'Users that were replied to, but are not part of previous groups', str(tweetCount[\"count\"]) ])\n",
    "    elif tweetCount[\"_id\"][\"user_type\"] == 'mention':\n",
    "        arr.append([ '5', tweetCount[\"_id\"][\"user_type\"], 'Users that were mentioned, but are not part of previous groups', str(tweetCount[\"count\"]) ])\n",
    "    else:\n",
    "        arr.append([ '6', tweetCount[\"_id\"][\"user_type\"], '', str(tweetCount[\"count\"]) ])        \n",
    "\n",
    "                      \n",
    "print (arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(arr)\n",
    "df.head(2)\n",
    "df.head(10)\n",
    "print(df.to_string())\n",
    "\n",
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "    \n",
    "    \n",
    "print_full(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in arr:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(BASE_PATH + '\\\\EDA.txt', 'w', encoding=\"utf-8\")\n",
    "\n",
    "for x in arr:\n",
    "    f.write(str(x))\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "display(HTML(df.to_html()))\n",
    "display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.sort_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.inventory.find( { item: null } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "\n",
    "total_tweets = 0    \n",
    "total_retweets = 0\n",
    "total_replies = 0\n",
    "\n",
    "select_cTweet = db.focusedTweet.aggregate([{\"$match\" : {\"retweeted_text\" : {\"$ne\": \"\"} }}, \n",
    "                                           {\"$group\": {\"_id\": {\"seq_agg\": \"$seq_agg\"}, \"count\": { \"$sum\": 1 } } } ])\n",
    "for tweetCount in select_cTweet:   \n",
    "    total_retweets = tweetCount[\"count\"]     \n",
    "                \n",
    "        \n",
    "select_cTweet = db.focusedTweet.aggregate([{\"$group\": {\"_id\": {\"seq_agg\": \"$seq_agg\"}, \"count\": { \"$sum\": 1 } } } ])\n",
    "for tweetCount in select_cTweet:            \n",
    "    total_tweets = tweetCount[\"count\"]\n",
    "        \n",
    "        \n",
    "select_cTweet = db.focusedTweet.aggregate([{\"$match\" : {\"in_reply_to_screen_name\" : {\"$ne\": \"None\"} }}, \n",
    "                                           {\"$group\": {\"_id\": {\"seq_agg\": \"$seq_agg\"}, \"count\": { \"$sum\": 1 } } } ])\n",
    "for tweetCount in select_cTweet:            \n",
    "    total_replies = tweetCount[\"count\"]\n",
    "\n",
    "arr.append([ 'Total Original Tweets', str(total_tweets-total_retweets-total_replies)])\n",
    "arr.append([ 'Total Replies', str(total_replies)])\n",
    "arr.append([ 'Total Retweets', str(total_retweets)])\n",
    "arr.append([ 'Total Tweets', str(total_tweets)])\n",
    "\n",
    "\n",
    "print(arr)\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
