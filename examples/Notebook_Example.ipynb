{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using **pyTwitterAnalysis** \n",
    "\n",
    "#### *This is a sample of some of the basic functionality available on pyTwitterAnalysis package*\n",
    "\n",
    "***\n",
    "\n",
    " ##### **What this notebook will do**:\n",
    " + load twitter raw json files into a mongoDB database\n",
    " * create mongoDB collection to analyze the data\n",
    " + create edges files based on user connections (mentions, quotes, replies, retweets)\n",
    " + create folder structure to save all files (by period or not)\n",
    " + create the following files for each folder and sub folder\n",
    "     + nodes with degrees \n",
    "     + edges\n",
    "     + texts for topics\n",
    "     + graph with lda model\n",
    "     + graph plot\n",
    "     + graph plot with contracted nodes\n",
    "     + hashtag & words frequency list\n",
    "     + hashtags & words barChart\n",
    "     + timeseries plot (tweet count & hashtag count(\n",
    "     + wordclouds (high degree nodes, high frequency hashtags, high frequency words)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyTwitterAnalysis as ta\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set your mongoDB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#db connection\n",
    "mongoDBConnectionSTR = \"mongodb://localhost:27017\"\n",
    "client = MongoClient(mongoDBConnectionSTR)\n",
    "db = client.twitter_DB_MeToo_Tst3 #chose your DB name here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the folder path you want to save all of the ouput files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = 'D:\\\\Data\\\\myTwitterAnalysisFiles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize you twitterAnalysis object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ta.tw_analysis(BASE_PATH, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data from json files nto a mongoDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_FILES_PATH = 'D:\\\\Data\\\\my_json_files'  ##this is the folder path where all of your twitter json files should be\n",
    "x.loadDocFromFile(JSON_FILES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create database collection that will be used to analyse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 100000   # You can set the number of tweets to load at a time. (Large number may cause out of memory errors, low number may take a long time to run)\n",
    "x.build_db_collections(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the periods you want to analyse \n",
    "#####  ** Set period_arr to None if you don't want to analyze separate periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format: Period Name, Period Start Date, Period End Date\n",
    "period_arr = [['P1',  '10/08/2017 00:00:00', '10/15/2017 00:00:00'],\n",
    "              ['P2',  '10/15/2017 00:00:00', '10/29/2017 00:00:00'],\n",
    "              ['P3',  '10/29/2017 00:00:00', '11/12/2017 00:00:00'],\n",
    "              ['P4',  '11/12/2017 00:00:00', '11/26/2017 00:00:00'],\n",
    "              ['P5',  '11/26/2017 00:00:00', '12/10/2017 00:00:00'],\n",
    "              ['P6',  '12/10/2017 00:00:00', '12/24/2017 00:00:00'],              \n",
    "              ['P7',  '12/24/2017 00:00:00', '01/07/2018 00:00:00'],              \n",
    "              ['P8',  '01/07/2018 00:00:00', '01/21/2018 00:00:00'],\n",
    "              ['P9',  '01/21/2018 00:00:00', '02/04/2018 00:00:00'],              \n",
    "              ['P10', '02/04/2018 00:00:00', '02/18/2018 00:00:00'],\n",
    "              ['P11', '02/18/2018 00:00:00', '03/04/2018 00:00:00'],\n",
    "              ['P12', '03/04/2018 00:00:00', '03/19/2018 00:00:00']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export edges\n",
    "##### This is an important step. We will use the files created here in other steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.export_all_edges_for_input(period_arr=period_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print initial EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.eda_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT STEP: Choose your settings here before running the next step\n",
    "##### These variables will help you decide what files you want to see and with which parameters \n",
    "##### Running the next step could take a long time. If you want to run piece by piece so you can see results soon, you can change the flags to 'Y' on at the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = BASE_PATH\n",
    "IS_BOT_FILTER = None\n",
    "PERIOD_ARR = period_arr \n",
    "\n",
    "#Choose which files you want to print - #Options: (Y/N)\n",
    "CREATE_NODES_EDGES_FILES_FLAG = 'Y'   \n",
    "CREATE_GRAPHS_FILES_FLAG = 'Y'\n",
    "CREATE_TOPIC_MODEL_FILES_FLAG = 'Y'\n",
    "CREATE_HT_FREQUENCY_FILES_FLAG = 'Y'\n",
    "CREATE_WORDS_FREQUENCY_FILES_FLAG = 'Y'\n",
    "CREATE_TIMESERIES_FILES_FLAG = 'Y'\n",
    "\n",
    "#topic settings\n",
    "NUM_OF_TOPICS = 6           #This is the number of topics to send as input to LDA model  (Default is 4)\n",
    "TOP_NO_WORD_FILTER = None   #The number of words to save on the frequency word list file. (Default=5000)\n",
    "\n",
    "\n",
    "#graph settings\n",
    "COMTY_CONTRACT_PER = 90   #This a percetage number used to remove nodes so we can be able to plot large graphs. \n",
    "                          #You can run this logic multiple times with different percentages. Each time will save the graph file with a different name\n",
    "GRAPH_PLOT_CUTOFF_NO_EDGES = 3000 #This is the number of edges cutoff to decide if we will print the graph or not. \n",
    "                                  #The logic will remove nodes until it can get to this number to plot\n",
    "                                  #Large number may take a long time to run. Small number may contract nodes too much or not print the graph at all\n",
    "\n",
    "\n",
    "#We will create subfolder for the top degree nodes based on these settings\n",
    "TOP_DEGREE_START=1   \n",
    "TOP_DEGREE_END=10\n",
    "\n",
    "#We will create subfolders for the top degree nodes for each period based on these settings\n",
    "PERIOD_TOP_DEGREE_START=1\n",
    "PERIOD_TOP_DEGREE_END=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This steps will create all the analysis files\n",
    "##### You can run this multiple times using different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.edge_files_analysis(output_path=OUTPUT_PATH,\n",
    "                      is_bot_Filter=IS_BOT_FILTER,\n",
    "                      period_arr=PERIOD_ARR,\n",
    "                      create_nodes_edges_files_flag=CREATE_NODES_EDGES_FILES_FLAG, \n",
    "                      create_graphs_files_flag=CREATE_GRAPHS_FILES_FLAG,\n",
    "                      create_topic_model_files_flag=CREATE_TOPIC_MODEL_FILES_FLAG,\n",
    "                      create_ht_frequency_files_flag=CREATE_HT_FREQUENCY_FILES_FLAG,\n",
    "                      create_words_frequency_files_flag=CREATE_WORDS_FREQUENCY_FILES_FLAG,\n",
    "                      create_timeseries_files_flag=CREATE_TIMESERIES_FILES_FLAG,\n",
    "                      num_of_topics=NUM_OF_TOPICS, \n",
    "                      top_no_word_filter=TOP_NO_WORD_FILTER, \n",
    "                      graph_plot_cutoff_no_edges=GRAPH_PLOT_CUTOFF_NO_EDGES, \n",
    "                      comty_contract_per=COMTY_CONTRACT_PER,\n",
    "                      top_degree_start=TOP_DEGREE_START,\n",
    "                      top_degree_end=TOP_DEGREE_END, \n",
    "                      period_top_degree_start=PERIOD_TOP_DEGREE_START, \n",
    "                      period_top_degree_end=PERIOD_TOP_DEGREE_END\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
