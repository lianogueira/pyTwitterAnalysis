{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using **pytwanalysis** - (**TwitterAnalysis**)\n",
    "\n",
    "#### *This is a sample of some of the basic functionality available on pyTwitterAnalysis package*\n",
    "\n",
    "***\n",
    "\n",
    " ##### **What this notebook will do**:\n",
    " + load twitter raw json files into a mongoDB database\n",
    " * create mongoDB collections to analyze the data\n",
    " + create edges files based on user connections (mentions, quotes, replies, retweets)\n",
    " + create folder structure to save all files (by period or not)\n",
    " + create the following files for each folder and sub folder\n",
    "     + nodes with degrees \n",
    "     + edges\n",
    "     + texts for topics\n",
    "     + graph with lda model\n",
    "     + graph plot\n",
    "     + graph plot with contracted nodes\n",
    "     + hashtag & words frequency list\n",
    "     + hashtags & words barChart\n",
    "     + timeseries plot (tweet count & hashtag count(\n",
    "     + wordclouds (high degree nodes, high frequency hashtags, high frequency words)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytwanalysis as ta\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set your mongoDB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#db connection\n",
    "mongoDBConnectionSTR = \"mongodb://localhost:27017\"\n",
    "client = MongoClient(mongoDBConnectionSTR)\n",
    "db = client.twitter_DB_Tst #choose your DB name here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the folder path you want to save all of the ouput files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = 'D:\\\\Data\\\\myTwitterAnalysisFiles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize you twitterAnalysis object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ta.TwitterAnalysis(BASE_PATH, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data from json files into a mongoDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the folder path where all of your twitter json files should be\n",
    "JSON_FILES_PATH = 'D:\\\\Data\\\\tests\\\\my_json_files'\n",
    "\n",
    "# Load json files into mongoDB\n",
    "x.loadDocFromFile(JSON_FILES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create database collections that will be used to analyse the data\n",
    "###### *Depending on the size of your data, this could take a while...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a file with a list of user ids that are bots, \n",
    "# you ca set the path of that file here. If not, set this variable to None\n",
    "bots_list_file = None\n",
    "\n",
    "# You can set the number of tweets to load at a time. \n",
    "# (Large number may cause out of memory errors, low number may take a long time to run)\n",
    "step = 100000\n",
    "\n",
    "# Build collections\n",
    "x.build_db_collections(step, bots_ids_list_file=bots_list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the periods you want to analyse \n",
    "#####  ** Set period_arr to None if you don't want to analyze separate periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format: Period Name, Period Start Date, Period End Date\n",
    "period_arr = [['P1',  '10/08/2017 00:00:00', '10/15/2017 00:00:00'],\n",
    "              ['P2',  '10/15/2017 00:00:00', '10/29/2017 00:00:00'],\n",
    "              ['P3',  '10/29/2017 00:00:00', '11/12/2017 00:00:00'],\n",
    "              ['P4',  '11/12/2017 00:00:00', '11/26/2017 00:00:00'],\n",
    "              ['P5',  '11/26/2017 00:00:00', '12/10/2017 00:00:00'],\n",
    "              ['P6',  '12/10/2017 00:00:00', '12/24/2017 00:00:00'],              \n",
    "              ['P7',  '12/24/2017 00:00:00', '01/07/2018 00:00:00'],              \n",
    "              ['P8',  '01/07/2018 00:00:00', '01/21/2018 00:00:00'],\n",
    "              ['P9',  '01/21/2018 00:00:00', '02/04/2018 00:00:00'],              \n",
    "              ['P10', '02/04/2018 00:00:00', '02/18/2018 00:00:00'],\n",
    "              ['P11', '02/18/2018 00:00:00', '03/04/2018 00:00:00'],\n",
    "              ['P12', '03/04/2018 00:00:00', '03/19/2018 00:00:00']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export edges\n",
    "###### This step will create edge files that will be used in the next steps\n",
    "###### If you skip this, the edge files will still get created when you run the analysis steps\n",
    "###### It can be useful to run this separetly in case you have a lot of data and want to see the time it takes for individual steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TYPE OF GRAPH EDGES\n",
    "########################################################\n",
    "# You can export edges for one type, or for all\n",
    "# Options: user_conn_all,       --All user connections\n",
    "#          user_conn_mention,   --Only Mentions user connections\n",
    "#          user_conn_retweet,   --Only Retweets user connections\n",
    "#          user_conn_reply,     --Only Replies user connections\n",
    "#          user_conn_quote,     --Only Quotes user connections\n",
    "#          ht_conn              --Hashtag connects - (Hashtgs that wereused together)\n",
    "#          all                  --It will export all of the above options\n",
    "\n",
    "TYPE_OF_GRAPH = 'all'\n",
    "\n",
    "x.export_mult_types_edges_for_input(period_arr=period_arr, type_of_graph=TYPE_OF_GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print initial EDA\n",
    "###### this will show you the summary information about your data. \n",
    "###### If your are not interested in the totals, you can skip to next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.eda_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT STEP: Choose your settings here before running the analysis\n",
    "##### These variables will help you decide what files you want to see and with which parameters \n",
    "##### Running the analysis step could take a long time. \n",
    "##### If you want to run piece by piece so you can see results soon, you can change the flags to 'Y' one at the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TYPE OF GRAPH ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TYPE OF GRAPH ANALYSIS\n",
    "########################################################\n",
    "# Type of graph analysis\n",
    "# Options: user_conn_all,       --All user connections\n",
    "#          user_conn_mention,   --Only Mentions user connections\n",
    "#          user_conn_retweet,   --Only Retweets user connections\n",
    "#          user_conn_reply,     --Only Replies user connections\n",
    "#          user_conn_quote,     --Only Quotes user connections\n",
    "#          ht_conn              --Hashtag connects - (Hashtgs that wereused together)\n",
    "\n",
    "TYPE_OF_GRAPH = 'user_conn_all'\n",
    "#------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OUTPUT PATH, PERIOD AND BOT SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OUTPUT PATH, PERIOD AND BOT SETTINGS\n",
    "########################################################\n",
    "\n",
    "# Path where you want to save your ouput files\n",
    "# It will use the path you already set previouly, \n",
    "# but you can change here in case you want a new path\n",
    "OUTPUT_PATH = BASE_PATH  \n",
    "\n",
    "#Filter bots or not. Options: (None, '0', or '1')\n",
    "IS_BOT_FILTER = None\n",
    "\n",
    "#Same period array you already set previously. \n",
    "#You can change here in case you want something new, \n",
    "#just follow the same format as array in previous step\n",
    "PERIOD_ARR = period_arr        \n",
    "#------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FILES TO CREATE OPTIONS\n",
    "###### Choose which files you want to create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILES TO CREATE OPTIONS\n",
    "# Choose which files you want to create \n",
    "########################################################\n",
    "\n",
    "\n",
    "# Creates a separate folder for the top degree nodes\n",
    "#------------------------------------------------------------\n",
    "CREATE_TOP_NODES_FILES_FLAG = 'Y'\n",
    "# IF you chose CREATE_TOP_NODES_FILES_FLAG='Y', you can also set these settings\n",
    "# We will create subfolder for the top degree nodes based on these number\n",
    "TOP_DEGREE_START = 1   \n",
    "TOP_DEGREE_END = 25\n",
    "# We will create subfolders for the top degree nodes \n",
    "# for each period based on these numbers\n",
    "PERIOD_TOP_DEGREE_START = 1\n",
    "PERIOD_TOP_DEGREE_END = 10\n",
    "\n",
    "\n",
    "# Creates files with the edges of each folder \n",
    "# and a list of nodes and their degree\n",
    "#------------------------------------------------------------\n",
    "CREATE_NODES_EDGES_FILES_FLAG = 'Y'\n",
    "\n",
    "\n",
    "# Creates the graph visualization files\n",
    "#------------------------------------------------------------\n",
    "CREATE_GRAPHS_FILES_FLAG = 'Y'\n",
    "\n",
    "\n",
    "# Creates files for topic discovery\n",
    "#------------------------------------------------------------\n",
    "# Tweet texts for that folder, word cloud, and LDA Model Visualization\n",
    "CREATE_TOPIC_MODEL_FILES_FLAG = 'Y'\n",
    "# If you chose CREATE_TOPIC_MODEL_FILES_FLAG='Y', you can also set this setting\n",
    "# This is the number of topics to send as input to LDA model (Default is 4)\n",
    "NUM_OF_TOPICS = 4\n",
    "\n",
    "\n",
    "# Creates files with ht frequency\n",
    "#------------------------------------------------------------\n",
    "# Text files with all hashtags used, wordcloud, and barchart\n",
    "CREATE_HT_FREQUENCY_FILES_FLAG = 'Y'\n",
    "\n",
    "\n",
    "# Creates files with word frequency\n",
    "#------------------------------------------------------------\n",
    "# Text files with all hashtags used, wordcloud, and barchart\n",
    "CREATE_WORDS_FREQUENCY_FILES_FLAG = 'Y'\n",
    "# If you answer yes to CREATE_WORDS_FREQUENCY_FILES_FLAG, then you can choose\n",
    "# how many words you want to see in your list file.\n",
    "# The number of words to save on the frequency word list file. (Default=5000)\n",
    "TOP_NO_WORD_FILTER = 5000   \n",
    "\n",
    "\n",
    "# Creates files with time series data\n",
    "#------------------------------------------------------------\n",
    "CREATE_TIMESERIES_FILES_FLAG = 'Y'\n",
    "\n",
    "\n",
    "# Creates graphs with hashtag information\n",
    "#------------------------------------------------------------\n",
    "# This can be used when you're analyzing user connections, \n",
    "# but still want to see the hashtag connection graph for that group of users\n",
    "CREATE_HT_CONN_FILES_FLAG = 'Y'\n",
    "# IF you chose CREATE_HT_CONN_FILES_FLAG = 'Y', you can also set this setting\n",
    "# This is to ignore the top hashtags in the visualization\n",
    "# Sometimes ignoring the main hashtag can be helpfull in visualization to\n",
    "# discovery other important structures within the graph\n",
    "TOP_HT_TO_IGNORE = 2\n",
    "\n",
    "\n",
    "# Creates louvain communities folder and files\n",
    "#------------------------------------------------------------\n",
    "CREATE_COMMUNITY_FILES_FLAG = 'N'\n",
    "# If set CREATE_COMMUNITY_FILES_FLAG = 'Y', then you can\n",
    "# set a cutoff number of edges to identify when a folder should be created\n",
    "# If the commty has less edges than this number, it won't create a new folder\n",
    "# Default is 200\n",
    "COMMTY_EDGE_SIZE_CUTOFF = 200 \n",
    "#------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "## GRAPH OPTIONS #######################################\n",
    "########################################################\n",
    "\n",
    "# In case you want to print full graph, with no reduction, and without node scale\n",
    "CREATE_GRAPH_WITHOUT_NODE_SCALE_FLAG = 'Y'\n",
    "# In case you want to print full graph, with no reduction, but with node scale\n",
    "CREATE_GRAPH_WITH_NODE_SCALE_FLAG = 'Y'\n",
    "# In case you want to print reduced graph\n",
    "CREATE_REDUCED_GRAPH_FLAG = 'Y'\n",
    "\n",
    "# This is the cutoff number of edges to decide if we will print \n",
    "# the graph or not. The logic will remove nodes until it can get \n",
    "# to this max number of edges to plot\n",
    "# If you choose a large number it may take a long time to run. \n",
    "# If you choose a small number it may contract nodes too much or not print the graph at all\n",
    "GRAPH_PLOT_CUTOFF_NO_NODES = 3000\n",
    "GRAPH_PLOT_CUTOFF_NO_EDGES = 10000\n",
    "\n",
    "\n",
    "# Reduced Graph settings\n",
    "#------------------------------------------------------------\n",
    "# This is a percentage number used to remove nodes\n",
    "# so we can be able to plot large graphs. \n",
    "# You can run this logic multiple times with different percentages. \n",
    "# Each time the logic will save the graph file with a different name \n",
    "# according to the parameter given\n",
    "REDUCED_GRAPH_COMTY_PER = 1\n",
    "    \n",
    "# Reduce graph by removing edges with weight less than this number\n",
    "# None if you don't want to use this reduction method\n",
    "REDUCED_GRAPH_REMOVE_EDGE_WEIGHT = None   \n",
    "\n",
    "# Continualy reduce graph until it gets to the GRAPH_PLOT_CUTOFF numbers or to 0\n",
    "REDUCED_GRAPH_REMOVE_EDGES_UNTIL_CUTOFF_FLAG = 'Y'\n",
    "#------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### UPDATE OBJECT WITH YOUR CHOICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set configurations\n",
    "x.setConfigs(type_of_graph=TYPE_OF_GRAPH,\n",
    "            is_bot_Filter=IS_BOT_FILTER,\n",
    "            period_arr=PERIOD_ARR,\n",
    "            create_nodes_edges_files_flag=CREATE_NODES_EDGES_FILES_FLAG, \n",
    "            create_graphs_files_flag=CREATE_GRAPHS_FILES_FLAG,\n",
    "            create_topic_model_files_flag=CREATE_TOPIC_MODEL_FILES_FLAG,\n",
    "            create_ht_frequency_files_flag=CREATE_HT_FREQUENCY_FILES_FLAG,\n",
    "            create_words_frequency_files_flag=CREATE_WORDS_FREQUENCY_FILES_FLAG,\n",
    "            create_timeseries_files_flag=CREATE_TIMESERIES_FILES_FLAG,\n",
    "            create_top_nodes_files_flag=CREATE_TOP_NODES_FILES_FLAG, \n",
    "            create_community_files_flag=CREATE_COMMUNITY_FILES_FLAG,\n",
    "            create_ht_conn_files_flag=CREATE_HT_CONN_FILES_FLAG,\n",
    "            num_of_topics=NUM_OF_TOPICS, \n",
    "            top_no_word_filter=TOP_NO_WORD_FILTER, \n",
    "            top_ht_to_ignore=TOP_HT_TO_IGNORE,\n",
    "            graph_plot_cutoff_no_nodes=GRAPH_PLOT_CUTOFF_NO_NODES, \n",
    "            graph_plot_cutoff_no_edges=GRAPH_PLOT_CUTOFF_NO_EDGES,\n",
    "            create_graph_without_node_scale_flag=CREATE_GRAPH_WITHOUT_NODE_SCALE_FLAG, \n",
    "            create_graph_with_node_scale_flag=CREATE_GRAPH_WITH_NODE_SCALE_FLAG, \n",
    "            create_reduced_graph_flag=CREATE_REDUCED_GRAPH_FLAG,\n",
    "            reduced_graph_comty_contract_per=REDUCED_GRAPH_COMTY_PER,\n",
    "            reduced_graph_remove_edge_weight=REDUCED_GRAPH_REMOVE_EDGE_WEIGHT, \n",
    "            reduced_graph_remove_edges=REDUCED_GRAPH_REMOVE_EDGES_UNTIL_CUTOFF_FLAG,                            \n",
    "            top_degree_start=TOP_DEGREE_START, \n",
    "            top_degree_end=TOP_DEGREE_END, \n",
    "            period_top_degree_start=PERIOD_TOP_DEGREE_START, \n",
    "            period_top_degree_end=PERIOD_TOP_DEGREE_END, \n",
    "            commty_edge_size_cutoff=COMMTY_EDGE_SIZE_CUTOFF\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This steps will create all the analysis files based on your settings\n",
    "##### You can run this multiple times using different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.edge_files_analysis(output_path=OUTPUT_PATH)\n",
    "\n",
    "print(\"**** END ****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
